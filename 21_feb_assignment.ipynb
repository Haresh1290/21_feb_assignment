{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bff5ca1-b76e-4e5c-81f3-572720b99284",
   "metadata": {},
   "source": [
    "Problem_1\n",
    "Also known as web data extraction and web harvesting, web scraping is the process of extracting data from a website. While you can do this manually, when projects require extracted data from hundreds or even thousands of web pages, automated web scraping tools can do the job more quickly and efficiently. \n",
    "\n",
    "Web scraping tools collect and export extracted data for in-depth analysis, typically into a central local database, spreadsheet, or API. \n",
    "\n",
    "Web scraping software may access the internet either through HTTP or a web browser, with the web crawler and web scraper working together to extract specific data from the web pages. We’ll discuss web crawlers and web scrapers in greater detail later in this article.\n",
    "\n",
    "Before data extraction can take place, it must fetch the webpage. Fetching refers to the process of downloading a web page. The browser does this every time a user visits a web page. The web page’s content is then parsed (i.e., analyzed for syntax), reformatted, or searched, with the extracted data then loaded into a database or copied into a spreadsheet.\n",
    "\n",
    "Data scraping has numerous applications across many industries—including insurance, banking, finance, trading, eCommerce, sports, and digital marketing. Data is also used to inform decision-making, generate leads and sales, manage risks, guide strategies, and create new products and services.\n",
    "\n",
    "\n",
    "Price Intelligence\n",
    "Price intelligence refers to monitoring a competitor’s prices and responding to their changes in pricing. Retailers use price intelligence to maintain a competitive edge over their rivals.\n",
    "\n",
    "Effective price intelligence involves web scraping, with eCommerce sellers extracting product and pricing information from other eCommerce websites to guide their pricing and marketing decisions.\n",
    "\n",
    "Price intelligence remains one of the most prominent use cases for web scraping due to valuable data for revenue optimization, product trend monitoring, dynamic pricing, competitor monitoring, and other applications. \n",
    "\n",
    "Market Research\n",
    "Web data extraction plays a vital role in market research. Market researchers use the resulting data to inform their market trend analysis, research and development, competitor analysis, price analysis, and other areas of study.\n",
    "\n",
    "Lead Generation\n",
    "Businesses that want to attract new customers and generate more sales need to launch effective sales and marketing campaigns. Web scraping can help companies gather the correct contact information from their target market—including names, job titles, email addresses, and cellphone numbers. Then, they can reach out to these contacts and generate more leads and sales for their business. \n",
    "\n",
    "Brand Monitoring\n",
    "Brands increasingly use social listening and monitoring tools to gauge the public’s perception of their brands. You can use web scraping software to extract real-time data from various sources (including social media platforms and review sites). You can then analyze the aggregated data to gauge brand sentiment. \n",
    "\n",
    "Business Automation\n",
    "In some cases, you may need to extract large amounts of data from a group of websites. You need to do this consistently, quickly, and structured. You can use web scraping tools to automatically extract these data sets. \n",
    "\n",
    "Real Estate\n",
    "You need web data extraction to generate the most up-to-date and accurate real estate listings. Web scraping is commonly used to retrieve the most updated data about properties, sale prices, monthly rental income, amenities, property agents, and other data points.\n",
    "\n",
    "Web scraped data also informs property value appraisals, rental yield estimates, and real estate market trends analysis. \n",
    "\n",
    "Alternative Data for Finance\n",
    "Web-scraped data is increasingly harnessed by investors to inform their trades and strategies. Use cases include: extracting insights from SEC filings, monitoring news and stock market performance, public sentiment integrations, and extracting stock market data from Yahoo Finance.\n",
    "\n",
    "News and Content Marketing\n",
    "Businesses, political campaigns, and nonprofits that need to keep a close eye on brand sentiment, polls, and other trends often invest in web scraping tools. Content and digital marketing agencies also use web scraping tools to monitor, aggregate, and parse the most critical stories from different industries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e68cb-8638-4051-87e9-8ca7d4bcc942",
   "metadata": {},
   "source": [
    "Problem_2\n",
    "Data Scraping Techniques\n",
    "Here are a few techniques commonly used to scrape data from websites. In general, all web scraping techniques retrieve content from websites, process it using a scraping engine, and generate one or more data files with the extracted content.\n",
    "\n",
    "HTML Parsing\n",
    "HTML parsing involves the use of JavaScript to target a linear or nested HTML page. It is a powerful and fast method for extracting text and links (e.g. a nested link or email address), scraping screens and pulling resources.\n",
    "\n",
    "DOM Parsing\n",
    "The Document Object Model (DOM) defines the structure, style and content of an XML file. Scrapers typically use a DOM parser to view the structure of web pages in depth. DOM parsers can be used to access the nodes that contain information and scrape the web page with tools like XPath. For dynamically generated content, scrapers can embed web browsers like Firefox and Internet Explorer to extract whole web pages (or parts of them).\n",
    "\n",
    "Vertical Aggregation\n",
    "Companies that use extensive computing power can create vertical aggregation platforms to target particular verticals. These are data harvesting platforms that can be run on the cloud and are used to automatically generate and monitor bots for certain verticals with minimal human intervention. Bots are generated according to the information required to each vertical, and their efficiency is determined by the quality of data they extract.\n",
    "\n",
    "XPath\n",
    "XPath is short for XML Path Language, which is a query language for XML documents. XML documents have tree-like structures, so scrapers can use XPath to navigate through them by selecting nodes according to various parameters. A scraper may combine DOM parsing with XPath to extract whole web pages and publish them on a destination site.\n",
    "\n",
    "Google Sheets\n",
    "Google Sheets is a popular tool for data scraping. Scarpers can use the IMPORTXML function in Sheets to scrape from a website, which is useful if they want to extract a specific pattern or data from the website. This command also makes it possible to check if a website can be scraped or is protected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f4b30-008b-4f1c-a54a-f0a8d6e1c614",
   "metadata": {},
   "source": [
    "Problem_3\n",
    "Beautiful Soup\n",
    "Beautiful Soup is a Python library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser and provides Pythonic idioms for iterating, searching, and modifying the parse tree.\n",
    "\n",
    "Uses of Beautiful Soup\n",
    "The Beautiful Soup library helps with isolating titles and links from webpages. It can extract all of the text from ​HTML tags, and alter the HTML ​in the document with which we’re working.\n",
    "\n",
    "Features of Beautiful Soup\n",
    "Some key features that make beautiful soup unique are:\n",
    "\n",
    "Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse tree.\n",
    "Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8.\n",
    "Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, which allows​ us to try out different parsing strategies or trade speed for flexibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2987070-fa48-4c53-be3f-bb48698fdb5c",
   "metadata": {},
   "source": [
    "Problem_4\n",
    "\n",
    "Scalable\n",
    "Size is everything, and Flask’s status as a microframework means that you can use it to grow a tech project such as a web app incredibly quickly. If you want to make an app that starts small, but has the potential to grow quickly and in directions you haven’t completely worked out yet, then it’s an ideal choice. Its simplicity of use and few dependencies enable it to run smoothly even as it scales up and up.\n",
    "\n",
    "Flexible\n",
    "This is the core feature of Flask, and one of its biggest advantages. To paraphrase one of the principles of the Zen of Python, simplicity is better than complexity, because it can be easily rearranged and moved around.\n",
    "\n",
    "Not only is this helpful in terms of allowing your project to move in another direction easily, it also makes sure that the structure won’t collapse when a part is altered. The minimal nature of Flask and its aptitude for developing smaller web apps means that it’s even more flexible than Django itself.\n",
    "\n",
    "Easy to negotiate\n",
    "Like Django, being able to find your way around easily is key for allowing web developers to concentrate on just coding quickly, without getting bogged down. At its core, the microframework is easy to understand for web developers, not just saving them time and effort but also giving them more control over their code and what is possible.\n",
    "\n",
    "Lightweight\n",
    "When we use this term in relation to a tool or framework, we’re talking about the design of it—there are few constituent parts that need to be assembled and reassembled, and it doesn’t rely on a large number of extensions to function. This design gives web developers a certain level of control.\n",
    "\n",
    "Flask also supports modular programming, which is where its functionality can be split into several interchangeable modules. Each module acts as an independent building block, which can execute one part of the functionality. Together this means that the whole constituent parts of the structure are flexible, moveable, and testable on their own.\n",
    "\n",
    "Documentation\n",
    "Following the creator’s own theory that “nice documentation design makes you actually write documentation,” Flask users will find a healthy number of examples and tips arranged in a structured manner. This encourages developers to use the framework, as they can easily get introduced to the different aspects and capabilities of the tool. You’ll find the Flask documentation on their official website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9e59f-9b3d-4e74-896f-e1fd7f9ecd44",
   "metadata": {},
   "source": [
    "Problem_5\n",
    "\n",
    "1. Amazon EC2 (Elastic Cloud Compute)\n",
    "Amazon EC2 is the fastest cloud computing service provided by AWS. It offers virtual, secure, reliable, and resizable servers for any workload. Through this service, it becomes easy for developers to access resources and also facilitates web-scale cloud computing. This comes with the best suitable processors, networking facilities, and storage systems. Developers can quickly and dynamically scale capacities as per business needs. It has over 500 instances and you can also choose the latest processor, operating system, storage, and networking to help you choose according to the needs of the business. Also, with Amazon EC2, you only have to pay for what you use, and also as per the time period, scale with amazon EC2 auto-scaling has optimal storage and can optimize CPU configurations.\n",
    "\n",
    "2. Amazon RDS (Relational Database Services) \n",
    "Amazon RDS (Relational Database Service) is another service provided by AWS which is a managed database for PostgreSQL, MariaDB, MySQL, and Oracle. Using Amazon RDS, you can set up, operate, and scale databases in the cloud. It provides high performance by automating the tasks like database setup, hardware provisioning, patching, and backups. Also, it helps in cost optimization by providing high availability, compatibility, and security for resources, and there’s no need to install and manage the database software. during its usage. As per the need, you can easily choose any engine out of 15+ engines some of them being MySQL, PostgreSQL, Oracle, etc. It is a highly secure and easily available AWS service.\n",
    "\n",
    "3. Amazon S3 (Simple Storage Service)\n",
    "With Amazon, it has become easy to store data anytime, anywhere. Amazon S3 (Simple Storage Service), one of the best services provided by AWS is an object storage service offering scalability, availability, security, and high-performing. You can also retrieve data, data here is stored in “storage classes” where there’s no requirement of extra investment and you can also manage it well. Amazon S3 is the perfect fit for big businesses where a large amount of data is managed for varied purposes. It comes with handling any volume of data with its robust access controls, and replication tools prevent accidental deletion, and also maintains data version controls. \n",
    "\n",
    "4. Amazon IAM (Identity and Access Management)\n",
    "Amazon IAM (Identity and Access Management) allows users to securely access and manage resources. To achieve complete access to the tools and resources provided by AWS, AWS IAM is the best AWS service. It gives you the right to have control over who has authorization (signed in) and authentication (has permissions) access to the resources. It comes with attribute-based access control which helps you to create separate permissions on the basis of the user’s attributes such as job role, department, etc. Through this, you can allow or deny access given to users. AWS IAM has complete access or is a central manager for refining permissions across AWS. He/She handles who can access what.\n",
    "\n",
    "5. Amazon EBS (Elastic Block Store)\n",
    "Amazon EBS is the next service provided by AWS which is a block storage solution specifically designed for Amazon EC2. Throughout a workload of any size, Amazon EBS helps to securely manage transactions. You can handle diverse workloads, be it relational, non-relational, or business applications. You get to choose between five different volume types so as to achieve effectiveness and optimum cost. It helps to resize workloads for big data analytics engines such as Hadoop and Spark. Its lifecycle management creates policies to create and manage backups effectively. It supports high-performance scaling workloads such as Microsoft, and SAP products. \n",
    "\n",
    "6. Amazon Lambda\n",
    "Another promising service by AWS is Amazon Lambda which is a serverless and event-driven computing service that lets you run code for virtual applications or backend services automatically. You need to worry about servers and clusters when working with solutions using Amazon Lambda. It is also cost-effective where you have to only pay for the services you use. As a user, your responsibility is to just upload the code and Lambda handles the rest. Using Lambda, you get precise software scaling and extensive availability. With hundreds to thousands of workloads per second, AWS Lambda responsibly handles code execution requests. It is one of the best services provided by AWS for developers.\n",
    "\n",
    "7. Amazon EFS (Elastic File System)\n",
    "Amazon EFS (Elastic File System) is a simple and serverless system where you can create and configure file systems without provisioning, deploying, patching, and maintaining. It is a scalable NFS file system made for use in AWS cloud services and on-premises resources. Also, it has no minimum fee or setup charge. You pay for the storage you use such as – \n",
    "\n",
    "for provisioned throughput\n",
    "automatically expand and shrink as per the addition and removal of files\n",
    "read and write access to data stored in Infrequent Access storage classes\n",
    "It is a scalable service where you can scale up to petabytes without thinking about the performance of the application. \n",
    "\n",
    "8. Amazon CloudFront\n",
    "Amazon CloudFront is an AWS service for content delivery networks, it delivers content globally, offering high performance and security and also at high transfer speeds and low latency(rate of time). It uses automated network mapping and intelligent routing mechanisms for delivering content to the destination. It has edge locations (worldwide network of data centers) used during content delivery. Using traffic encryptions and access controls, you can also enhance the security of data. It seamlessly integrates with systems like Amazon S3, Amazon EC2, and Lambda to manage custom code. Also, there’s no additional data transfer fee when connected with Amazon S3 and Amazon EC2.\n",
    "\n",
    "\n",
    "9. Amazon SNS (Simple Notification Service)\n",
    "It is a web service provided by AWS, which is a fully managed solution for messaging having low-cost infrastructure. It is used for bulk message delivery and direct chat with the customers through system-to-system or app-to-person between decoupled microservice apps. It is used to easily set up, operate, and send notifications from the cloud. It is a messaging service between Application to Application (A2A) and Application to Person (A2Person), and sends notifications in two ways – A2A and A2P. A2P allows many-to-many messaging between microservices, distributed systems, and event-driven serverless applications, allowing you to send messages to customers with SMS texts, email, and push notifications. \n",
    "\n",
    "10. Amazon VPC (Virtual Private Cloud)\n",
    "Another AWS service is Amazon VPC (Virtual Private Cloud) which is an isolated cloud resource, it enables you to set up an isolated section where you can deploy AWS resources at scale in a virtual environment. This service is responsible to control the virtual networking environment such as resource placement, security, and connectivity. Security can be improved by applying rules for outbound and inbound connections. Also, it detects anomalies in the patterns, troubleshoots network connections, prevents data leakage, and handles configuration issues. Using VPC, you get complete access to control the environment, such as choosing IP address, subset creation, and route table arrangement. \n",
    "\n",
    "11. Amazon Auto-Scaling\n",
    "Amazon Auto-Scaling is one of the best services provided by AWS, it examines the applications and adjusts its capacity accordingly which is to maintain predictable performance at the lowest possible cost. It becomes easy to scale up applications for multiple resources across services in seconds. To meet the demands of the business, it scales computing capacity and this can be achieved by adding or removing EC2 instances automatically. There are two types of scaling –  dynamic (presently changing demands) and predictive (response based on predictions) scaling. It can be used with Amazon EC2 Auto Scaling to dynamically scale your Amazon EC2 instances and also it receives the right resource at the right time.\n",
    "\n",
    "Must Read: What are the Important AWS Cloud Services?\n",
    "\n",
    "12. Amazon SQS (Simple Queue Service)\n",
    "Amazon SQS (Simple Queue Service) lets you store, send, and receive messages between software components through a polling method at any volume without any data loss. It uses the FIFO technique to guarantee the message is processed once in sequential order. It allows the decoupling and scaling of microservices, distributed systems, and serverless apps. Through SQS, you can manage message queuing services to exchange data anytime and anywhere. \n",
    "\n",
    "13. Amazon Elastic Beanstalk\n",
    "Amazon Elastic Beanstalk is an AWS service used for deployment and scaling web applications developed using Java, PHP, Python, Docker, etc. It supports running and managing web applications. You just need to upload your code and the deployment part is handled by Elastic Beanstalk (from capacity provisioning, load balancing, and auto-scaling to application health monitoring). It is the best service for developers since it takes care of the servers, load balancers, and firewalls. Also, you can have control over AWS assets and the other resources required for the application. You get the benefit of paying for what you use, thus maintaining cost-effectiveness.  \n",
    "\n",
    "14. Dynamo DB\n",
    "DynamoDB is a serverless, document database key-value NoSQL database that is designed to run high-performance applications. It can manage up to 10 trillion requests on a daily basis and support thresholds of more than 20 million requests per second. DynamoDB has built-in security with a fully-managed multi-master, multi-region, durable database, and in-memory archiving for web-scale applications. It has in-built tools which is used to generate actionable insights, useful analytics, and monitor traffic trends. It offers built-in security, continuous backups, automated multi-region replication, data import and export, and in-memory caching. \n",
    "\n",
    "15. Amazon ElastiCache\n",
    "Amazon ElastiCache is a fully-managed, in-memory caching AWS service. Its responsibility is to accelerate the performance of the application and database by reducing the latency to microseconds. You can easily access data from in-memory with high-speed, microsecond latency, and high throughput. It sets up, runs, and scales up data storage in the cloud. It is considered the best option for use cases in real-time examples such as session stores, gaming, caching, and live analytics. It is also very compatible with open-source caching technologies such as Redis and Memcached. Since, it’s a self-managed cache service, thereby making it is cost-effective. \n",
    "\n",
    "16. Amazon Cloud Directory\n",
    "Amazon Cloud Directory is a specialized graph-based directory providing a foundational building block for developers. It automatically scales up to millions of objects and it also provides an extensible schema shared with multiple applications. It reduces the time usage as you just have to define the schema, create a directory, and populate it by making calls to the API. You can create directories for various uses such as course catalogs, organizational charts, and registries. Also, with Cloud Directory, it’s possible to increase the flexibility of creating directories with hierarchies with multiple dimensions. You can also search for the parent objects along a dimension without creating multiple queries. It is also integrated with AWS CloudTrail (log the date, time, and identity of users who accesses the directory data) and resource tagging(tag your directories and schemas).\n",
    "\n",
    "17. Amazon Cognito\n",
    "Amazon Cognito is also one of the best services provided by AWS. It is an identity management service used for user identity and data synchronization where you can securely manage and synchronize data for millions of users. It is responsible for administering a control access dashboard for onboarding users through sign-in, and sign-up to the web and mobile apps like Apple, Facebook, Google, and Amazon. The login feature is possible with social identity providers and SAML for the best customer experience and also offers high-end security. It has a feature called ‘Cognito user pools’ that can be set up without any infrastructure. It also supports strong authentication and encryption of data. \n",
    "\n",
    "18. Amazon Inspector\n",
    "Amazon Inspector is an automated vulnerability management service that scans AWS workloads for software vulnerabilities and unintended network exposure. It discovers and scans EC2 instances, and container images in Amazon Elastic Container Registry. It creates a finding where it describes the vulnerability, identifies the affected resource, rates the seriousness, and provides remediation guidance. After finding the vulnerability, it quickly rectifies it before the application worsens. Also, it provides accurate risk scores and streamlined workflow. It manages multiple Amazon Inspector accounts. \n",
    "\n",
    "19. AWS Aurora\n",
    "AWS Aurora is an RDBMS (Relational Database Management System) which is built with MySQL and PostgreSQL for the cloud. It is a high-performing compatible database that is five times faster than MySQL. You can reduce the cost and enhance its security, reliability, and availability. Also, it is cost-effective by reducing the cost to one-tenth. Some very important tasks such as database setup and backup, hardware provisioning, and patching can be automated using AWS Aurora. It is a serverless entity used to build SAAS applications and modernize enterprise applications. \n",
    "\n",
    "20. Amazon S3 Glacier\n",
    "Amazon S3 Glacier is the archive storage at a low cost. It is a long-term, secure, durable storage class for data archiving at the lowest cost and milliseconds of access. Its storage classes are generally built for data archiving, providing high-performance, and retrieval flexibility and is also cost-effective. It is built with three storage classes namely – S3 Glacier instant retrieval, flexible retrieval, and deep archive. Each has its purpose, the instant class provides immediate access to data, and the flexible class provides flexible access. and deep archive helps in archiving compliance data and digital media. \n",
    "\n",
    "21. Amazon Cloudwatch\n",
    "Amazon CloudWatch detects uncommon changes in the environment, set an alert, troubleshoots issues, and take automated actions. With this, you can track the complete stack, and use logs, alarms, and events data to take actions and thereby focusing on building the application, resulting in the growth of the business. It is the best service designed for developers, DevOps engineers, site reliability engineers, and IT managers. With Amazon CloudWatch, you can detect anomalies in the environment. With this single platform, you can monitor all AWS resources and applications quickly. It monitors application performance and optimizes resources. \n",
    "\n",
    "22. AWS Firewall Manager\n",
    "AWS Firewall Manager is the central management service that helps you centrally configure and manage firewall rules across applications. It creates firewall rules, and security policies and implements them across the infrastructure. While adding new resources to the service, you can protect them using AWS Firewall Manager. Also, it monitors DDoS attacks across the organization. Its main objective is to protect applications hosted on EC2 instances, and continually audit resources. \n",
    "\n",
    "23. AWS Key Management Service (KMS)\n",
    "AWS KMS (Key Management Service) lets you create, manage, and control cryptographic keys across the application and thus protects the data. This is also integrated with more than 100 AWS services to encrypt data and control access to the keys that decrypt it. You can centrally manage keys and define policies, perform operations (signing) using asymmetric key pairs to validate signatures, validate JSON web tokens by generating HMACs to ensure integrity and authenticity securely, and encrypt data with AWS Encryption SDK data encryption library. \n",
    "\n",
    "24. Amazon LightSail\n",
    "Amazon LIghtSail is a VPS (Virtual Private Server) where developers, small businesses, and users can get started and find a solution to build and host their applications on the cloud. It offers VPS instances, databases, containers, and storage. It can be integrated with AWS Lambda (to create, test, and delete sandboxes with ideas) to run your code and provide the best computing service. Pre-configured applications can be built using Amazon LightSail. It resources are virtual machines, SSD-based storage, static IP, and data transfer. You can configure access, networking, and security environments automatically.\n",
    "\n",
    "25. Amazon SageMaker\n",
    "Amazon SageMaker is an AWS service that has a full-fledged machine learning service that data scientists, business analysts, and developers use to build, train, and deploy high-quality models. It is an analytical tool used to analyze data more efficiently. After analyzing, it generates reports and also provides the purpose of generating predictions. You can access, label, and process large amounts of structured and unstructured data, and automate and standardize MLOps practices and governance to support auditability and transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8504d36-90cf-4e85-a0f4-155aa1a95c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
